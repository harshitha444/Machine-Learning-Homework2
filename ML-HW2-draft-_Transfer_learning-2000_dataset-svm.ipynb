{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    "                         Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D,\\\n",
    "                          UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.models import Model, Input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try validation with another dataset, not the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.framework.test_util.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "#     a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "#     b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "#     c = tf.matmul(a, b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'D:\\sapienza\\ML\\MWI-Dataset-1.1_2000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = 'D:\\sapienza\\ML\\Weather_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "input_shape = ()\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\\\n",
    "    zoom_range=0.4,\\\n",
    "    rotation_range=60,\\\n",
    "    width_shift_range=0.3,\\\n",
    "    height_shift_range=0.3,\\\n",
    "    horizontal_flip=True,\\\n",
    "    shear_range=0.3,\n",
    "    zca_whitening=True,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    vertical_flip=False)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=datadir,\n",
    "    target_size=(125,125),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=testdir,\n",
    "    target_size=(125, 125),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "num_samples = train_generator.n\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "classnames = [k for k,v in train_generator.class_indices.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(input_shape):  \n",
    "    input0 = Input(shape=input_shape)\n",
    "\n",
    "    # load a pretrained model on imagenet without the final dense layer\n",
    "    feature_extractor = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=input0)\n",
    "    feature_extractor = feature_extractor.output\n",
    "    feature_extractor = Model(input=input0, output=feature_extractor)\n",
    "    feature_extractor.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizers.SGD(lr=1e-4,momentum=0.9,nesterov=True), metrics=['accuracy'])\n",
    "    return feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "feature_extractor=feature_extractor(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # set the feture extractor layers as non-trainable\n",
    "for idx,layer in enumerate(feature_extractor.layers):\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "val_steps = test_generator.n//test_generator.batch_size+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(feature_extractor):\n",
    "    input_t = feature_extractor.get_layer(index=0).input\n",
    "\n",
    "    output_extractor = feature_extractor.get_layer(name = 'block5_pool').output\n",
    "    \n",
    "    #output_extractor = MaxPooling2D(pool_size=(4,4))(output_extractor)\n",
    "\n",
    "    # flat the output of a Conv layer\n",
    "    flatten = Flatten()(output_extractor) \n",
    "    #add regularizer!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #version 2: feed the features to an svm\n",
    "    \n",
    "    #flatten_norm= regularizers.l2(0.01)(flatten_norm)\n",
    "    flatten_norm = BatchNormalization()(flatten)\n",
    "    model = Model(input=input_t, output=flatten_norm, name=\"Reccurent_svm\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizers.SGD(lr=1e-3,nesterov=True,momentum=0.9), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"Reccurent_svm\", inputs=Tensor(\"in..., outputs=Tensor(\"ba...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model=get_model(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718592 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1048576 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 4. Skipping tag 41486\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41487\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41486\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    }
   ],
   "source": [
    "X_train= model.predict_generator(train_generator,steps=steps_per_epoch,use_multiprocessing=True,workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(penalty='l2', loss='squared_hinge',multi_class='ovr',C=0.1)\n",
    "svm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=model.predict_generator(test_generator,val_steps,use_multiprocessing=True,workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32323897300855825"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.09      0.09      0.09       521\n",
      "           2       0.48      0.36      0.41      1421\n",
      "           3       0.52      0.38      0.44      1096\n",
      "\n",
      "   micro avg       0.32      0.32      0.32      3038\n",
      "   macro avg       0.27      0.21      0.24      3038\n",
      "weighted avg       0.42      0.32      0.37      3038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predicted,labels=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True                 Predicted         \terrors \terr % \n",
      "------------------------------------------------------------------\n",
      "SNOWY            ->  HAZE              \t329 \t10.83 % \n",
      "SUNNY            ->  SNOWY             \t305 \t10.04 % \n",
      "SNOWY            ->  RAINY             \t304 \t10.01 % \n",
      "SNOWY            ->  SUNNY             \t274 \t9.02 % \n",
      "RAINY            ->  SNOWY             \t261 \t8.59 % \n",
      "SUNNY            ->  RAINY             \t197 \t6.48 % \n",
      "SUNNY            ->  HAZE              \t174 \t5.73 % \n",
      "RAINY            ->  SUNNY             \t119 \t3.92 % \n",
      "RAINY            ->  HAZE              \t93 \t3.06 % \n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, predicted)\n",
    "\n",
    "conf = [] # data structure for confusions: list of (i,j,cm[i][j])\n",
    "for i in range(0,cm.shape[0]):\n",
    "    for j in range(0,cm.shape[1]):\n",
    "        if (i!=j and cm[i][j]>0):\n",
    "            conf.append([i,j,cm[i][j]])\n",
    "\n",
    "col=2\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:,col])]  # decreasing order by 3-rd column (i.e., cm[i][j])\n",
    "\n",
    "print('%-16s     %-16s  \\t%s \\t%s ' %('True','Predicted','errors','err %'))\n",
    "print('------------------------------------------------------------------')\n",
    "for k in conf:\n",
    "    print('%-16s ->  %-16s  \\t%d \\t%.2f %% ' %(classnames[k[0]],classnames[k[1]],k[2],k[2]*100.0/test_generator.n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
